# Core
# Machine Functions that will be the engines that would pull all of those `enum`, `structs`, `implementation`
Higher level view
```text
[Input: AgentPrompt + Role + ToolChoice + SchemaFields]
                   │
                   ▼
         ┌─────────────────────┐
         │  machine_agent()    │◄────────────────┐
         │  (calls machines:)  │                 │
         │  ├── machine_prompt()                 │
         │  ├── machine_model_settings()         │
         │  ├── machine_struct_output()          │
         │  └── machine_tools() (optional)       │
         └─────────┬───────────┘                 │
                   ▼                             │
         [Constructed Agent Struct]              │
                   │                             │
                   ▼                             │
         ┌────────────────────────────┐          │
         │  machine_api_call()        │──────────┤
         │  (send Agent to LLM)       │          │
         └─────────────┬──────────────┘          │
                       ▼                         │
         ┌────────────────────────────┐          │
         │  machine_api_response()    │          │
         │  ├─ Check if tool call     │          │
         │  ├─ Save tool_call_id      │          │
         │  ├─ Append to MessageHistory │        │
         │  └─ Call tools if needed   │          │
         └─────────────┬──────────────┘          │
                       ▼                         │
                [Next message] ──────────────────┘
                       │
                       ▼
           Loop until: no tool call OR list exhausted
```

# Contruction Machines
| Machine                       | Purpose                                                                 |
| ----------------------------- | ----------------------------------------------------------------------- |
| `machine_prompt(...)`         | Returns `MessagesSent` from role & prompt string                        |
| `machine_struct_output(...)`  | Builds `Schema`, stores into `StructOut` (using `SchemaFieldDetails`)   |
| `machine_tools(...)`          | Returns `Vec<HashMap<String, serde_json::Value>>` from tool descriptors |
| `machine_model_settings(...)` | Combines tool\_choice, tool list, prompts → `ModelSettings`             |
| `machine_agent(...)`          | Final wrapper: assembles all into a complete `Agent`                    |

# Agent Machines
| Field               | Generated By               |
| ------------------- | -------------------------- |
| `role`              | input                      |
| `message`           | input                      |
| `prompt`            | `machine_prompt()`         |
| `structured_output` | `machine_struct_output()`  |
| `task_state`        | default                    |
| `llm`               | `machine_model_settings()` |


# Response Machines
| Machine                       | Purpose                                                                 |
| ----------------------------- | ----------------------------------------------------------------------- |
| `machine_api_call(agent)`     | Sends current `Agent` as payload, receives response                     |
| `machine_api_response(...)`   | Parses `LlmResponse`, detects tool calls, extracts tool\_call\_id       |
| `machine_tool_loop(...)`      | Executes loop until tool is no longer called or tool list is exhausted  |
| `machine_context_update(...)` | Trims and appends latest messages to `MessageHistory` (limit to N msgs) |
| `machine_final_answer(...)`   | Synthesizes all tool answers and final LLM answer                       |

# Loop Control Strategy
Depicted like almost how the funciton would look like
- Use Agent.llm.tool_choice to determine if tools should be tried.
- After every API call:
  - Use ResponseFormat.schema to match structured output
  - If tool_calls present:
    - Save to MessageHistory
    - Create new message with tool_call_id
    - Call API again
    - Repeat until no tool is suggested

# Some Rules
- Limit Messages: MessageHistory should be pruned with .truncate() or .split_off() if over limit
- Flexible Tool Choice: use enum ChoiceTool::Auto | Required | None to decide per agent


# Planned Response Machines
| Machine Name             | Purpose                                                              |
| ------------------------ | -------------------------------------------------------------------- |
| `machine_api_call`       | Sends the constructed agent as JSON payload to the Cerebras endpoint |
| `machine_api_response`   | Parses `LlmResponse`, checks for `tool_calls`                        |
| `machine_tool_loop`      | Reconstructs the message with tool\_call result and loops until done |
| `machine_context_update` | Manages a limited message history (e.g. last 3 messages)             |
| `machine_final_answer`   | Extracts or synthesizes the final assistant message                  |

# Diagram High Level Execution
             +------------------+
             | machine_agent()  |
             +--------+---------+
                      |
                      v
             +--------+---------+
             | machine_api_call |
             +--------+---------+
                      |
                      v
             +--------+---------+
             | machine_api_response (check tool_calls)
             +--------+---------+
                      |
          +-----------+-------------+
          |                         |
       tool_call?                 none
          |                         |
          v                         v
  +-------+--------+         +------+--------+
  | machine_tool_loop |     | machine_final_answer |
  +-------+--------+         +------+--------+
          |
  +-------v--------+
  | machine_context_update |
  +------------------------+

